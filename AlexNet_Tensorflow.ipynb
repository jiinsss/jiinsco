{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet_Tensorflow.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEBhXTOmVe_W"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def AlexNet(\n",
        "  input_shape=None,\n",
        "  weights=None,\n",
        "  classes=1000,\n",
        "  classifier_activation='softmax'):\n",
        "  \n",
        "  model = tf.keras.Sequential([\n",
        "      #특징 추출 부분 \n",
        "      #Conv 1\n",
        "      tf.keras.layers.Conv2D(filters=96, #output channel이 96\n",
        "                              kernel_size=(11, 11),\n",
        "                              strides=4,#보폭\n",
        "                              padding=\"valid\", #제로패딩을 수행하지 않겠다(=작아지는 경우에도 그냥 두겠다)\n",
        "                              activation=tf.keras.activations.relu, #relu\n",
        "                              input_shape=input_shape),\n",
        "      #Max Pool 1\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                strides=2,\n",
        "                                padding=\"valid\"),\n",
        "      tf.keras.layers.BatchNormalization(), #배치정규화\n",
        "      #Conv 2\n",
        "      tf.keras.layers.Conv2D(filters=256,\n",
        "                              kernel_size=(5, 5),\n",
        "                              strides=1,\n",
        "                              padding=\"same\",\n",
        "                              activation=tf.keras.activations.relu),\n",
        "      #Max Pool 2\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                strides=2,\n",
        "                                padding=\"same\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      #Conv 3\n",
        "      tf.keras.layers.Conv2D(filters=384,\n",
        "                              kernel_size=(3, 3),\n",
        "                              strides=1,\n",
        "                              padding=\"same\",\n",
        "                              activation=tf.keras.activations.relu),\n",
        "      #Conv 4\n",
        "      tf.keras.layers.Conv2D(filters=384,\n",
        "                              kernel_size=(3, 3),\n",
        "                              strides=1,\n",
        "                              padding=\"same\",\n",
        "                              activation=tf.keras.activations.relu),\n",
        "      #Conv 5\n",
        "      tf.keras.layers.Conv2D(filters=256,\n",
        "                              kernel_size=(3, 3),\n",
        "                              strides=1,\n",
        "                              padding=\"same\",\n",
        "                              activation=tf.keras.activations.relu),\n",
        "      #Max Pool 3\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                strides=2,\n",
        "                                padding=\"same\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      \n",
        "      tf.keras.layers.Flatten(),#뽑아준 특징을 flatten해서 분류충에 넣어줄 준비를 해줌\n",
        "      \n",
        "      #분류 층 부분\n",
        "      #Fully connected layer 1 , \n",
        "      tf.keras.layers.Dense(units=4096,\n",
        "                            activation=tf.keras.activations.relu),\n",
        "      tf.keras.layers.Dropout(rate=0.2),\n",
        "      #Fully connected layer 2\n",
        "      tf.keras.layers.Dense(units=4096,\n",
        "                            activation=tf.keras.activations.relu),\n",
        "      tf.keras.layers.Dropout(rate=0.2),\n",
        "      \n",
        "      #Fully connected layer 3 #최종 출력층\n",
        "      tf.keras.layers.Dense(units=classes,#학습에 사용한 데이터셋 개수에 맞게 아웃풋 지정\n",
        "                            activation=tf.keras.activations.softmax)#확률값인 softmax를 출력해줘야하니까\n",
        "                            \n",
        "  ])\n",
        "\n",
        "  return model"
      ]
    }
  ]
}